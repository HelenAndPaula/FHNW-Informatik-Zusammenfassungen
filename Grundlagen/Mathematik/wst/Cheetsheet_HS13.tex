\documentclass[landscape,twocolumn,a4paper]{article}

\setlength{\oddsidemargin}{-.6in}	 % default=0in
\setlength{\textwidth}{11in}	 % default=9in
\setlength{\columnsep}{0.25in}	 % default=10pt
\setlength{\columnseprule}{1pt}	 % default=0pt (no line)
\setlength{\textheight}{7.5in}	 % default=5.15in
\setlength{\topmargin}{-1.0in}	 % default=0.20in
\setlength{\headsep}{0.25in}	 % default=0.35in
\setlength{\parskip}{1.2ex}
\setlength{\parindent}{0mm}
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{5pt}{-5pt}
\titlespacing*{\subsection}{0pt}{0pt}{-5pt}
\titlespacing*{\subsubsection}{0pt}{0pt}{-5pt}


%Math
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{ulem}
\usepackage{stmaryrd} %f\UTF{00FC}r Blitz!
\usepackage{tikz}

\usepackage{multirow}
\usepackage{multicol}


%PageStyle
\usepackage[ngerman]{babel} % deutsche Silbentrennung
\usepackage[utf8]{inputenc} 
\usepackage{fancyhdr, graphicx}
\usepackage[scaled=0.8]{helvet}
%\usepackage{enumitem}
\usepackage{parskip}
%\usepackage[a4paper,top=2cm]{geometry}
%\setlength{\textwidth}{17cm}
%\setlength{\oddsidemargin}{-0.5cm}


%My Commands
\newcommand{\RN}{\mathbb{R}} %Real Number
\newcommand{\NN}{\mathbb{N}} %Natural Number
\newcommand{\QN}{\mathbb{Q}} %Rational Number
\newcommand{\ZN}{\mathbb{Z}} %ganze Zahlen
\newcommand{\CN}{\mathbb{C}}
\newcommand{\PN}{\mathbb{P}} %Primzahle Bitches
\newcommand{\Teilt}{\mid} %|
\newcommand{\Teiltn}{\nmid} %kein teiler
\newcommand{\Potp}{\mathcal{P}} %Potenzmenge
\newcommand{\Pota}{\mathcal{A}}
\newcommand{\Potr}{\mathcal{R}}
\newcommand{\Potn}{\mathcal{N}}
\newcommand{\Bold}[1]{\textbf{#1}} %Boldface
\newcommand{\Kursiv}[1]{\textit{#1}} %Italic
\newcommand{\T}[1]{\text{#1}} %Textmode
\newcommand{\Nicht}[1]{\T{\sout{$ #1 $}}} %Streicht Shit durch
\newcommand{\lra}{\leftrightarrow} %Arrows
\newcommand{\ra}{\rightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\lral}{\longleftrightarrow}
\newcommand{\ral}{\longrightarrow}
\newcommand{\lal}{\longleftarrow}
\newcommand{\Lra}{\Leftrightarrow}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\La}{\Leftarrow}
\newcommand{\Lral}{\Longleftrightarrow}
\newcommand{\Ral}{\Longrightarrow}
\newcommand{\Lal}{\Longleftarrow}
\newcommand{\Vektor}[1]{\vec{#1}}
\newcommand{\Brace}[1]{\left( #1 \right)} %()
\newcommand{\Bracel}[1]{\left\lbrace #1 \right.} %(
\newcommand{\Bracer}[1]{\right. #1 \right\rbrace} %)
\newcommand{\Brack}[1]{\left\lbrace #1 \right\rbrace} %{}
\newcommand{\Brackl}[1]{\left\lbrace #1 \right.} %{
\newcommand{\Brackr}[1]{\right. #1 \right\rbrace} %}
\newcommand{\Result}[1]{\underline{\underline{#1}}} %Doppelt unterstrichen
\newcommand{\Abs}[1]{\left| #1 \right|} %Absolutbetrag
\newcommand{\Norm}[1]{\Abs{\Abs{ #1 }}} %Norm
\newcommand{\Arrays}[1]{\left(\begin{array}{c}#1\end{array}\right)} %Array mit einer Kolonne ()
\newcommand{\Array}[2]{\left(\begin{array}{#1}#2\end{array}\right)} %Array mit n Kolonnen ()
\newcommand{\Bracka}[2]{\left\lbrace\begin{array}{#1}#2\end{array}\right\rbrace} %Array mit {}
\newcommand{\Brackal}[2]{\left\lbrace\begin{array}{#1} #2 \end{array}\right.} %Array mit {
\newcommand{\Brackar}[2]{\left.\begin{array}{#1} #2 \end{array}\right\rbrace} %Array mit }
\newcommand{\Sumone}[2]{\sum_{#2=1}^{#1}} %Summe von 1
\newcommand{\Sumz}[2]{\sum_{#2=0}^{#1}} %Summe von 0
\newcommand{\Sum}[2]{\sum_{#2}^{#1}} %Allgemeine Summe
\newcommand{\Oneover}[1]{\frac{1}{#1}} %1 über igendwas
\newcommand{\Tablewt}[3]{\begin{table*}[h]\caption{#1} \begin{tabular}{#2}{#3}\end{tabular}\end{table*}} %Table mit Titel
\newcommand{\Oben}[2]{\overset{#1}{#2}} %etwas über etwas anderem
\newcommand{\Unten}[2]{\underset{#1}{#2}} %etwas unter etwas anderem
\newcommand{\Bildcap}[2]{\begin{figure}[htb]\centering\includegraphics[width=0.2\textwidth]{#1} \caption{#2}\end{figure}} %Bild mit beschriftung
\newcommand{\Bildjpeg}[1]{\includegraphics[width=0.2\textwidth]{#1.jpeg}} %Bilder jpeg!!
\newcommand{\Bildjpg}[1]{\includegraphics[width=0.2\textwidth]{#1.jpg}} %Bilder jpg!!
\newcommand{\Bild}[1]{\includegraphics[width=0.4\textwidth]{#1}} %Bilder jpg!!
%Beispiel für lstlisting \lstinputlisting[label=Aufgabe 4a,caption=Aufgabe 4a]{4a.java}




%Config
\renewcommand{\headrulewidth}{0pt}
\setlength{\headheight}{15.2pt}

%Metadata
\title{
	\vspace{5cm}
	WST Cheetsheet
}
\author{ Jan Fässler}
\date{5. Semester (HS 2013)}


% hier beginnt das Dokument
\begin{document}
\subsubsection*{Laplace-Experiment}
\begin{equation*}
  P(E)=\frac{|E|}{|\Omega|}=\frac{\text{Anzahl günstige Ergebnisse}}{\text{Anzahl aller Ergebnisse}} \rightarrow \text{Gleichverteilung}
\end{equation*}
\subsubsection*{Produkte}
\begin{equation*}
  |A_1 \times A_2 \times \dots \times A_k| = |A_1| * |A_2| * \dots * |A_k|
\end{equation*}
\subsubsection*{Summen}
\begin{equation*}
  |A_1 \cup A_2 \cup \dots \cup A_k| = |A_1| + |A_2| + \dots + |A_k|
\end{equation*}
\subsubsection*{Fakultät}
\begin{equation*}
	n! := n*(n-1)* \dots *2*1 \sim \sqrt{2*\pi*n}*(\frac{n}{e})^n
\end{equation*}

\subsubsection*{Binominalkoeffizient}

\begin{equation*}
	 \binom{n}{k} := \frac{n!}{(n-k)!*k!}
\end{equation*}

\subsubsection*{Urnenmodel}
\begin{center}
	\begin{tabular}{l|l|l}
		 					&	zur\"{u}cklegen			&	nicht zur\"{u}cklegen\\
		 \hline
		 geordnet		&	$n^k$							&	$n!$ oder $\frac{n!}{(n-k)!}$\\
		 \hline
		 ungeordnet	&	$\binom{k+n-1}{k}$	&	$\binom{n}{k}=\frac{n!}{k!(n-k)!}$
	\end{tabular}
\end{center}

\subsubsection*{algemeine Wahrscheinlichkeiten}
\begin{align*}
	 P(E_1 \cup E_2 \cup E_3 \cup  \dots ) = P(E_1) + P(E_2) + P(E_3) + \dots \\	 
	 \forall E_1, E_2 \subseteq \Omega : P(E_1\cup E_2) = P(E_1) + P(E_2) - P(E_1 \cap E_2)\\
	 E=\{e_1,e_2, \dots \} \rightarrow P(E) = P(\{e_1\}) + P(\{e_2\}) + \dots
\end{align*}

\subsubsection*{Z-Dichte}
Die Funktion $f_P : \Omega \rightarrow [0,1]$ mit $f_P(w)=P(\{w\})$ heisst Zähldichte von P.
\begin{align*}
	 P(E) &=\sum_{e \in E} f_P(e) \\
	 P(E) &=\sum_{e \in \Omega} f_P(e)=1
\end{align*}

\subsubsection*{bedingte Wahrscheinlichkeit}
Es sei $B \subseteq \Omega$ mit $P(B) > 0$. Dann heisst $P(A|B)$ (elementare) bedingte Wahrscheibnlichkeit von A unter B.
\begin{equation*}
	 P(A|B) := \frac{P(A \cap B)}{P(B)}
\end{equation*}

\subsubsection*{Formel von Bayes}
\begin{equation*}
	 P(A|B)=\frac{P(A)}{P(B)} * P(B | A)
\end{equation*}

\subsubsection*{totele Wahrscheinlichkeit}
Es sei  $B_i(i \in I)$ eine Zerlegung von $\Omega$ (d.h. die $B_i$ sind paarweise disjunkt und $\Omega=U_{i \in I} B_i$) mit $P(B_i) > 0$.
\begin{equation*}
	 P(A) = \sum_{i \in I} P(A | B_i) * P(B_i)
\end{equation*}

\subsubsection*{positive prädiktive Wert}
Für $0 < P(A) < 1$ gilt mit $\Omega = A \cup A^c$ insbesondere:
\begin{equation*}
	 P(A | B) = \frac{P(A)*P(A | B)}{P(B | A) * P(A) + P(B | A^c) * P(A^c)}
\end{equation*}

\subsubsection*{stochastische Unabhängigkeit}
Zwei Ereignisse $A,B \subseteq \Omega$ heissen stochastisch unabhängig, falls 
\begin{equation*}
	P(A \cap B) = P(A) * P(B)  \equiv \underbrace{P(A|B)}_{\frac{P(A \cap B)}{P(B)}}=P(A) \leftarrow (B) \neq 0]
\end{equation*}

\subsubsection*{Mehrstufige Zufallsexperimente}
Gegeben ist eine Urne mit 4 weissen und 2 schwarzen Kugeln. Wir ziehen dreimal ohne Zurücklegen: Was ist die Warhscheinlichkeit A: \"{ }Dritte Kugel weiss\"{}? \\
$\Omega = \{w,s\} \times \{w,s\} \times \{w,s\}$ und $A= \{(w,w,w),(w,s,w),(s,w,w),(s,s,w)\}$
\begin{equation*}
	P(A) = f(w,w,w) + f(w,s,w) + f(s,w,w) + f(s,s,w)
\end{equation*}

\subsubsection*{Verteilungsfunktion}
Es sei $X : \Omega \rightarrow X$ eine Zufallsvariable, wobei $X \in \RN$ eine endliche oder abzählbare Menge ist. Zudem sei $f$ die Zähldichte von $X$.
\begin{equation*}
	F(x)=P(X \leq x) = \sum_{t \in X:t \leq x} f(t)
\end{equation*}

\subsubsection*{Erwartungswert, Varianz \& Standardabweichung}
\begin{align*}
	E(X) &=\sum_{x \in X} x * f(x)=\sum_{x \in X} x * P(X = x) \\
	V(X)&= \sum_{x \in X} (x - E)^2 * f(x) = \sum_{x \in X} (x - E)^2 * P(X=x) = E(X^2)-E(X)^2 \\
	\sigma(X) &= \sqrt{V(X)}
\end{align*}

\subsubsection*{Bernoulli-Verteilung}
kann zwei Werte annehmen, 0 (Treffer) oder 1 (kein Treffer)
\begin{align*}
	X \sim B(p): P(0) &= 1 - p \\
	P(1) &= p \\
	E(X) &= p \\
	V(X) &= p*(1-p)
\end{align*} 

\subsubsection*{Binomial-Verteilung}
Anzahl Treffer (Wahrscheinlichkeit $p$) in $n$ unabhängigen Versuchen
\begin{align*}
	X \sim Bin(n,p): P(X=k) &= \binom{n}{k} * p^k * (1-p)^{n-k}, k=0,1, \dots, n \\
	E(X) &= n*p \\
	V(X) &= n*p*(1-p)
\end{align*} 
\textbf{Dichte}: binopdf($k$, $n$, $p$) $\mid$ \textbf{Verteilungsfunktion}: binocdf($k$, $n$, $p$)


\subsubsection*{geometirsche-Verteilung}
Versuche bis erster Treffer (Wahrscheinlichkeit $p$) in $n$ unabhängigen Veruschen
\begin{align*}
	X \sim Geo(n,p): P(X=k) &= (1-p)^{k-1}*p, k=0,1, \dots, n \\
	E(X) &= \frac{1}{p}\\
	V(X) &= \frac{1-p}{p^2}
\end{align*} 
\textbf{Dichte}: geopdf($k-1$, $p$) $\mid$ \textbf{Verteilungsfunktion}: geocdf($k-1$, $p$)

\subsubsection*{Poisson-Verteilung}
Verteilung für seltene Ereignisse mit im Schnitt $\lambda$ Ereignisse pro Zeit/Ort
\begin{align*}
	X \sim Poi(\lambda): P(X = k) &=\frac{\lambda^k}{k!}*e^{-\lambda}, k=0,1, \dots, n \\
	E(X) &= \lambda\\
	V(X) &= \lambda
\end{align*} 
\textbf{Dichte}: poisspdf($k$, $\lambda$) $\mid$ \textbf{Verteilungsfunktion}: poisscdf($k$, $\lambda$)

\subsection*{stetige Zufallsvariable}
$\rightarrow$ kontinuierlicher Wertebereich\\
$\rightarrow$ beschreibt Wahrscheinlichkeit das ZV Wert in Bereich annimmt.\\
$\rightarrow$ Wahrscheinlichkeit als Dichte ausgedrückt.
\begin{align*}
Dichtefunktion &: P(a \leq X \leq b) = \int _a^b f(x) dx \\
Erwartungswer &t: E(X) =\int _{-\infty}^{\infty} x*f(x) dx \\
Varianz &: V(X) = \int _{-\infty}^{\infty} (x - E(X))^2 * f(x) dx = E(X^2) - E(X)^2 \\
Standartabweichung &: \sigma(X) = \sqrt{V(X)} \\
Verteilungsfunktion &: F(x) = P(X \leq x) = \int _{-\infty}^{x}f(t)dt\\
\end{align*}

\subsubsection*{stetige Gleichverteilung-Verteilung}
die konstante Dichte  für $s \leq x \leq t$ auf dem Intervall$[s,t]$. 
\begin{align*}
	X \sim U[s,t]&: f(x)=\frac{1}{t-s} \\
	E(x) &= \frac{s + t}{2}\\
	V(x) &= \frac{1}{12}*(t-s)^2
\end{align*} 

\subsubsection*{Standardormalverteilung} 
\begin{align*}
	X \sim N(0,1)&: \varphi(x) = \frac{1}{\sqrt{2\pi}}*e^{-\frac{x^2}{2}} \\
	E(x) &= 0\\
	V(x) &= 1
\end{align*} 
\textbf{Dichte}: normpdf($x$) $\mid$ \textbf{Verteilungsfunktion}: normcdf($x$)

\subsubsection*{Normalverteilung}
Die Normalverteilung mit Parametern $\mu$ und $\sigma$.
\begin{align*}
	X \sim N(\mu, \sigma) &: \varphi(x) = \frac{1}{\sqrt{2\pi\sigma^2}}*e^{-\frac{(x-\mu)^2}{2\sigma^2}}  \\
	E(x) &= \mu\\
	V(x) &= \sigma
\end{align*} 
\textbf{Dichte}: normpdf($x$, $\mu$, $\sigma$) $\mid$ \textbf{Verteilungsfunktion}: normcdf($x$, $\mu$, $\sigma$)

\textbf{Standardisierung:} $X \sim M(\mu, \sigma) \rightarrow X-\mu \sim N(0,\sigma) \rightarrow Z \sim N(0,1) \text{ mit } Z=\frac{x-\mu}{\sigma}$ \\
\textbf{Quantil:} Gegeben $\alpha \in (0,1)$. Für welche $z_\alpha$ gilt P($x\leq z_\alpha=\alpha$) \\
\textbf{Matlab:} $x=$ norminv($p$)


\subsubsection*{Exponentialverteilung}
Die Wahrscheinlichkeit dass X einen Wert grösser als $t$ annimt, sinkt exponentiell.
\begin{align*}
	X \sim Exp(\lambda) : P(X \geq t) &= e^{-\lambda t} \\
	E(x) &= \frac{1}{\lambda}\\
	V(x) &= \frac{1}{\lambda^2}
\end{align*} 
\textbf{Dichte}: exppdf($k$, $\frac{1}{\lambda}$) $\mid$ \textbf{Verteilungsfunktion}: expcdf($k$, $\frac{1}{\lambda}$)

\subsubsection*{Eigenschaften}
\begin{align*}
	E(X + Y) &= E(X) + E(Y) \\
	E(a * X) &= a * E(X) \\
	E(X + c) &= E(X) + c\\
	V(X + c) &= V(X) \\
	V(a * X) &= a^2* V(X) \\
	E(g(X)) &= \sum_{x} g(x) * P(X=x) \leftarrow [\RN \rightarrow \RN] \\
	E(g(X)) &\neq g(E(X))
\end{align*} 

\subsubsection*{Unabhängigkeit}
\begin{align*}
P(X_1 \leq x_1, X_2 \leq x_2, \dots, X_n \leq x_n) &= P(X_1 \leq x_1) * P(X_2 \leq x_2), \dots, P(X_n \leq x_n) \\
P(g(X,Y) = z) &= \sum_{x \in \chi} \sum_{y\in \Upsilon:g(x,y)=z} f_X(x) * f_Y(y) \\
X \sim Poi(\lambda_1), Y \sim Poi(\lambda_2) &\Rightarrow X + Y \sim Poi(\lambda_1 + \lambda_2) \\
X \sim Bin(n_1,p), Y \sim Bin(n_2,p) &\Rightarrow X + Y \sim Bin(n_1 + n_2, p)
\end{align*}

\subsubsection*{Additionstheorem der Normalverteilung}
\begin{align*}
a_1X_1 + a_2X_2 + \dots + a_nX_n \sim N(a_1\mu_1 + a_2\mu_2 + \dots + a_n\mu_n, \sqrt {a_1^2 \sigma_1^2 + a_2^2 \sigma_2^2 +\dots + a_n^2 \sigma_n^2})
\end{align*}
\subsubsection*{Eigenschaft von Erwartungswert und Varianz}
Es seien $X$ und $Y$  Zufallsvariablen und $a, c \in \RN$.
Dan gilt:
\begin{align*}
E(X + Y) = E(X) + E(Y) \\
E(aX) = aE(X) \\
E(X + c) = E(X) + c\\
V(X + c) = V(X)\\
V(aX) = a^2V(X)\\
\text{Falls X und Y unabhängig sind: } V(X + Y) = V(X) + V(Y) \\
\text{Wenn X diskret ist und } f_X \text{die Zählichte von X: } E(g(X)) = \sum_x g(x) * f_X(x) \\
\text{Wenn X stetig ist und } f_X \text{ ide Dichte von X: } E(g(X)) = \int_{-\infty}^\infty g(x) * f_X(x) dx
\end{align*}

\subsubsection*{Ungleichung von Tschabyscheff}
\begin{equation*}
P(\mid X - \mu \mid \geq k) \leq \frac{\sigma^2}{k^2}
\end{equation*}
Diese Abschätzung gilt für alle möglichen Verteilungen von X. Sie ist deshalb in manchen Fällen recht grob.

\subsubsection*{Grentzwertsätze: Gesetz der Grossen Zahlen}
\begin{equation*}
P(\mid \frac{X}{n} - p \mid \geq \epsilon) \rightarrow 0 (n \rightarrow \infty)
\end{equation*}
\subsubsection*{Zentraler Grenzwertsatz}
\begin{align*}
  S_n = X_1 .. + X_n
  \mu_n = n.\mu \\
  \sigma_n = \sqrt{n}. \sigma
  \frac{S_n - \mu_n}{\sqrt{n}. \sigma} ~N(0,1)
\end{align*}

\subsubsection*{Moivre und Laplace Grenzwertsatz}
$Bin(n,p)$ als Summe von n $B(p)$ variablen
\begin{align*}
 P(a \le X \le b) \approx \sigma(\frac{b-np}{\sqrt{np(1-p}}) - \sigma(\frac{a-np}{\sqrt{np(1-p)}})
\end{align*}

\subsubsection*{T Verteilung}
Benutzt um $\sigma$ zu Schätzen: (\textit{ t verteilt mit n-1 Freiheitsgraden})
\begin{align*}
 T = \sqrt{n} \frac{\overline{X}-\mu}{\sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (X_i-\overline{X})^2}}
\end{align*}

\subsubsection*{Statistische Tests}
\begin{enumerate}
	\item Man stellt die Nullhypothese $H_0$ und die Alternativhypothese $H_1$ auf. Das bestmögliche Ergebnis ist die Widerlegung von $H_0$
	\item Man wählt ein Testverfahren zb Experimente oder Stichproben
	\item Aufgrund des gewählten Tests bestimmt man die so genannte Testgrösse
	\item Man wählt ein Signifikanzniveau $\alpha$ und bestimmt aufgrund dessen den Verwerfungsbereich. Dieser wird so festgelegt, dass bei Zutreffen von $H_0$ die Testgrösse mit Wahrscheinlichkeit $\leq \alpha$ dort drin liegt. 
	\item Liegt der gemäss (3) berechnete Wert der Testgrösse im Verwerfungsbereich, so lehnen wir $H_0$ ab. Man sagt in diesem Fall, auch, das Ergebniss des Tests sei signifikant auf dem $\alpha$-niveau
\end{enumerate}
\subsubsection*{Konfidenzintervall}
\begin{align*}
	\frac{X-np}{\sqrt{np(1-p)}} \sim N(0,1) \\
	\alpha=\frac{1+Q}{2} \\
\left[\frac{1}{n+z_\alpha^2} \left(X+\frac{z_\alpha^2}{2}-z_\alpha\sqrt{\frac{X(n-X)}{n}+\frac{z_\alpha^2}{4}}\right), \frac{1}{n+z_\alpha^2} \left(X+\frac{z_\alpha^2}{2}+z_\alpha\sqrt{\frac{X(n-X)}{n}+\frac{z_\alpha^2}{4}}\right)\right] \\
	\left[\frac{k}{n}-\frac{z_\alpha}{n}\sqrt{\frac{k(n-k)}{n}}, \frac{k}{n}+\frac{z_\alpha}{n}\sqrt{\frac{k(n-k)}{n}} \right]
\end{align*}

\subsubsection*{Hypothesen}
\begin{description}
 \item $H_0$ Nullhypothese / $H_1$ Alternativhypothese
 \item[Fehler 1 Art:] $H_O$ trifft zu aber verwerfen.
 \item[Fehler 2 Art:] $H_0$ trifft \textbf{nicht} zu aber nicht verwerfen
 \item[Signigikanzniveau] $\alpha$ Verwerfungsbereich - Wahrscheinlichkeit für F. 1 Art höchstens $\alpha$
 \item $ X \in V_{bereich} \rightarrow H_0$ ungültig das Gegenteil gilt auch. Gegenteil ist aber zu schwach für 
definitven Beweis. 
\end{description}
--------------------------------------------------------------------------------------------------------
\\
by Jan Fässler

\end{document} 