\documentclass[a4paper, 11pt]{article} % ISO-8859-1 - latin1

%Math
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{ulem}
\usepackage{stmaryrd} %f\UTF{00FC}r Blitz!

%PageStyle
\usepackage[ngerman]{babel} % deutsche Silbentrennung
\usepackage[ansinew]{inputenc} % wegen deutschen Umlauten
\usepackage{fontenc}
\usepackage{fancyhdr, graphicx} %for header/footer
\usepackage{wasysym}
\usepackage{fullpage}
\usepackage{textcomp}

% Listings
\usepackage{color}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{caption}

% Commands
\newcommand{\Bold}[1]{\textbf{#1}} %Boldface
\newcommand{\Kursiv}[1]{\textit{#1}} %Italic
\newcommand{\T}[1]{\text{#1}} %Textmode
\newcommand{\Nicht}[1]{\T{\sout{$ #1 $}}} %Streicht Shit durch
\newcommand{\lra}{\leftrightarrow} %Arrows
\newcommand{\ra}{\rightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\lral}{\longleftrightarrow}
\newcommand{\ral}{\longrightarrow}
\newcommand{\lal}{\longleftarrow}
\newcommand{\Lra}{\Leftrightarrow}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\La}{\Leftarrow}
\newcommand{\Lral}{\Longleftrightarrow}
\newcommand{\Ral}{\Longrightarrow}
\newcommand{\Lal}{\Longleftarrow}

% Code listenings
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
 
\lstdefinestyle{JavaStyle}{
 language=Java,
 basicstyle=\footnotesize\ttfamily, % Standardschrift
 numbers=left,               % Ort der Zeilennummern
 numberstyle=\tiny,          % Stil der Zeilennummern
 stepnumber=5,              % Abstand zwischen den Zeilennummern
 numbersep=5pt,              % Abstand der Nummern zum Text
 tabsize=2,                  % Groesse von Tabs
 extendedchars=true,         %
 breaklines=true,            % Zeilen werden Umgebrochen
 frame=b,         
 %commentstyle=\itshape\color{LightLime}, Was isch das? O_o
 %keywordstyle=\bfseries\color{DarkPurple}, und das O_o
 basicstyle=\footnotesize\ttfamily,
 stringstyle=\color[RGB]{42,0,255}\ttfamily, % Farbe der String
 keywordstyle=\color[RGB]{127,0,85}\ttfamily, % Farbe der Keywords
 commentstyle=\color[RGB]{63,127,95}\ttfamily, % Farbe des Kommentars
 showspaces=false,           % Leerzeichen anzeigen ?
 showtabs=false,             % Tabs anzeigen ?
 xleftmargin=17pt,
 framexleftmargin=17pt,
 framexrightmargin=5pt,
 framexbottommargin=4pt,
 showstringspaces=false      % Leerzeichen in Strings anzeigen ?        
}

%Config
\renewcommand{\headrulewidth}{0pt}
\setlength{\headheight}{15.2pt}
\pagestyle{plain}

%Metadata
\title{Algorithmen \& Datenstrukturen 2}
\author{Jan Fässler}
\date{3. Semester (HS 2012)}
\fancyfoot[C]{If you use this documentation for a exam, you should offer a beer to the authors!}

% hier beginnt das Dokument
\begin{document}

% Titelbild
\maketitle
\thispagestyle{fancy}

\newpage

% Inhaltsverzeichnis
\pagenumbering{Roman}
\tableofcontents	  	


\newpage
\setcounter{page}{1}
\pagenumbering{arabic}

% Inhalt Start

\section{Listen}
Eine verkettete Liste (linked list) ist eine dynamische Datenstruktur zur Speicherung von Objekten. Sie eignen sich für das speichern einer unbekannten Anzahl von Objekten, sofern kein direkter Zugriff auf die einzelnen Objekte benötigt wird. Jedes Element in einer Liste muss neben den Nutzinformationen auch die notwendigen Referenzen zur Verkettung enthalten.\\ 
Es gibt drei verschiedene Arten von Listen:\\
\begin{center}
\includegraphics[scale=0.4]{listen.png}
\end{center}

\lstinputlisting[language=java,caption=einfache Linked List,style=JavaStyle]{linked_list.java}


\subsection{Stack}
Der Stack ist eine dynamische Datanstruktur bei der man nur auf das oberste Element des Stabels zugreifen (top), ein neues Element auf den Stabel legen (push) oder das oberste Element des Stapels entfernen (pop) kann.
\lstinputlisting[language=java,caption=Implementierung eines Stacks,style=JavaStyle]{stack.java}

\subsection{Erweiterte Liste}
Dies ist mal eine mögliche und vor allem nur teilweise Implementierung einer doppelt verlinkten Liste. Die Implementierung des Iterators und der sortierung sind ausgeklammert in Unterkapitel.
\lstinputlisting[language=java,caption=Liste mit Iterator,style=JavaStyle]{advanced_list.java}

\subsubsection{Iterators}
Die Schnittstelle java.util.Iterator, erlaubt das Iterieren von Containerklassen. Jeder Iterator stellt Funktionen namens next(), hasNext() sowie eine optionale Funktion namens remove() zur Verfügung. Der folgende ListIterator stellt auch noch Funktionen für rückwertsiterieren zur Verfügung, sowie die Möglichkeit den aktuellen Index abzufragen. Zudem kann damit noch direkt über den Iterator Elemente eingefügt oder ersetzt werden.

\lstinputlisting[language=java,caption=Iterators,style=JavaStyle]{linked_list_iterators.java}

\subsubsection{Merge Sort}
\lstinputlisting[language=java,caption=Merge Sort,style=JavaStyle]{linked_list_mergesort.java}

\subsection{Skip-Liste}
Die Skip-Liste ist eine sortierte, einfach verkettete Liste, die uns aber ein schnelleres Suchen von Elementen in der Datenstruktur erlaubt. In einer sortierten, verketteten Liste müssen wir jedes Element einzeln durchlaufen bis wir das gewünschten Element gefunden haben. Wenn wir nun aber in der sortierten Liste auf jedem zweiten Element eine zusätzliche Referenz auf zwei Elemente weiter hinten setzen, dann reduziert sich die Anzahl zu besuchender Elemente auf einen Schlag um rund die Hälfte. Genau betrachtet müssen wir nie mehr als $(n/2) + 1$ Elemente besuchen (n ist die Länge der Liste). 
\begin{center}
\includegraphics[scale=0.65]{skip_liste.png}
\end{center}

\subsubsection{Beispiel}
\lstinputlisting[language=java,caption=Skip List,style=JavaStyle]{skip_liste.java}

\newpage
\section{Bäume}
Bäume sind verallgemeinerte Listenstrukturen. Ein Element, üblicherweise spricht man von Knoten (node), hat nicht, wie im Falle linearer Listen, nur einen Nachfolger, sondern eine endliche, begrenzte Anzahl von Söhnen. In der Regel ist einer der Knoten als Wurzel (root) des Baumes ausgeprägt. Das ist zugleich der einzige Knoten ohne Vorgänger. Jeder andere Knoten hat einen (unmittelbaren) Vorgänger, der auch Vater des Knotens genannt wird. Eine Folge $p_0$, ..., $p_k$ von Knoten eines Baumes, die die Bedingung erfüllt, dass $p_i+1$ Sohn von $p_i$ ist für $0 \leq i <$ k, heisst Pfad (path) mit Länge k, der $p_0$ mit $p_k$ verbindet. Jeder von der Wurzel verschiedene Knoten eines Baumes ist durch genau einen Pfad mit der Wurzel verbunden.
\begin{center}
\includegraphics[scale=0.65]{tree.png}
\end{center}

\subsection{Binäre Suchbäume}
Ein binärer Suchbaum ist ein geordneter Baum mit Ordnung d = 2. In jedem Knoten wird ein Suchschlüssel so abgespeichert, dass alle Suchschlüssel des linken Teilbaums des Knotens kleiner und alle Suchschlüssel des rechten Teilbaums des Knotens grösser sind. Das heisst, dass an jedem Knoten alle kleineren Suchschlüssel über den linken Sohn und alle grösseren Suchschlüssel über den rechten Sohn erreicht werden.\\
Die so geordneten Knoten in einem balancierten binären Suchbaum erlauben ein schnelles Suchen. Der maximale Suchaufwand hängt direkt von der Höhe des Baumes ab und wächst nur logarithmisch mit der Anzahl der Knoten im Baum.
	
\subsubsection{Traversieren}
Das Durchlaufen kann auf mindestens drei verschiedene Arten erfolgen: Preorder, Inorder, Postorder.
\begin{description}
	\item[Inorder] \hfill \\
		1. traversiere den linken Teilbaum des Knotens v; 2. besuche den Knoten v; 3. traversiere den rechten Teilbaum des Knotens v.
	\item[Preorder] \hfill \\
		Bei Preorder wird zuerst Knoten v besucht, dann erst 99 der linke Teilbaum von v in Preorder und anschliessend noch der rechte Teilbaum von v in Preorder durchlaufen.
	\item[Postorder] \hfill \\
		Hier wird zuerst der linke Teilbaum von v, dann der rechte Teilbaum von v und erst zum Schluss der Knoten v besucht.
\end{description}

\subsection{Balancierte Bäume}
Ein binärer Suchbaum ist AVL-ausgeglichen oder höhenbalanciert oder eben ein AVL- Baum, wenn für jeden Knoten v des Baumes gilt, dass sich die Höhe des linken Teilbaumes von der Höhe des rechten Teilbaumes von v höchstens um eins unterscheidet. \\

\subsubsection{Berechnungen}

h := Höhe = Maximal auftretende Tiefe\\
$bal(t) := h(t_r) - h(t_l) ~// \in [-1,0,1] \Ra $ AVL-Baum\\

\subsubsection{Einfügen}
\Bold{Fall 1: p hat 1 Sohn}, einfügen an der leeren Stelle: \\
einf. Links: $bal(p) =+ 1 \rightarrow bal(p) = 0$\\
einf. Rechts: $bal(p) =- 1 \rightarrow bal(p) = 0$ \\
Höhe des Sohnes: $h(p) = const$ / Balance des Vater: $bal(v) = const$ \\
$\Ra$ \Bold{fertig} \\
\\
\Bold{Fall 2: p hat keine Söhne}, einfügen links/rechts \\
einf. links/rechts:$ bal(p) =\pm 1$ \\
Schieflage: ++$h(p)$ 
\begin{description}
	\item[Variante a.)] \hfill \\
		$bal(v) \neq 0$ / p ist kürzerer Ast $\Ra bal(v)=0$ \\
		\& $h(v)=const$ $\Ra$ \Bold{fertig}
	\item[Variante b.)] \hfill \\
		$bal(v) = 0$ $\Ra bal(v)=\pm1$ \\
		\& ++$h(v)$ $\Ra$ \Bold{weiter testen mit Vater/Opa/...}
	\item[Variante c.)] \hfill \\
		$bal(v) \neq 0$ \& p ist längerer Ast \\
		$\Ra bal(v)=\pm2! \Ra$ \Bold{es muss balaciert werden:} \\
\end{description}
\begin{tabular}{|l|l|}
	\hline 
	$sgn(bal(v))=sgn(bal(p))$ & $sgn(bal(v)) \neq sgn(bal(p))$ \\
	\hline 
	& \\
	\includegraphics[scale=0.5]{rotation_right.png} & \includegraphics[scale=0.45]{rotation_left_right.png} \\
	\hline
\end{tabular}

\subsubsection{Löschen}
Bei einem nicht ALV Baum ist der Aufwand für das löschen eines Elementes überschaubar:
\begin{description}
	\item[I) p hat keinen Sohn] \hfill \\
		p entfernen
	\item[II) p hat einen Sohn] \hfill \\
		p entfernen und Sohn nachziehen
	\item[III) p hat zwei Söhne] \hfill \\
		p entfernen, durch nächstkleineres oder nächstgrösseres Element ersetzen \\
		(dies kann eventuell zu einer weiteren Löschoperation vom Typ II weiter unten führen)
\end{description}
Bei einem ALV Baum muss nach dem löschen noch balanciert werden.

\subsubsection{Beispiel}
\lstinputlisting[language=java,caption=Insert \& Delete from a AVL Tree,style=JavaStyle]{avl-operations.java}

\subsection{Heaps / Priority-Queues}
Die wichtigsten Operationen bei Warteschlangen (queues) sind der Zugriff auf das vorderste Objekt, das Einfügen eines Objektes am Ende der Warteschlange und das Entfernen des vordersten Objektes. Solche einfache Warteschlangen werden üblicherweise mit verketteten Listen realisiert. \\
Die wichtigsten Operationen von Prioritätswarteschlangen unterscheiden sich leicht von denjenigen der einfachen Warteschlangen. Der Zugriff auf das vorderste Objekt wird durch den Zugriff auf ein Objekt mit höchster Priorität ersetzt. Entsprechend wird das Entfernen des vordersten Objektes durch das Entfernen eines Objektes mit höchster Priorität ersetzt. Schliesslich wird ein neues Objekt nicht einfach am Ende eingefügt, sondern es muss an der richtigen Position gemäss seiner Priorität eingereiht werden. Dabei muss die richtige Position aber zuerst gesucht werden.

\subsubsection{Bedingungen}
Man unterscheidet Heaps in Min-Heaps und Max-Heaps. Bei Min-Heaps bezeichnet man die Eigenschaft, dass die Schlüssel der Kinder eines Knotens stets größer als der Schlüssel ihres Vaters sind, als Heap-Bedingung. Dies bewirkt, dass an der Wurzel des Baumes stets ein Element mit minimalem Schlüssel im Baum zu finden ist. Umgekehrt verlangt die Heap-Bedingung bei Max-Heaps, dass die Schlüssel der Kinder eines Knotens stets kleiner als die ihres Vaters sind. Hier befindet sich an der Wurzel des Baumes immer ein Element mit maximalem Schlüssel.

\subsubsection{Element mit höchster Priorität entfernen}
Das eigentliche Entfernen eines Objektes mit höchster Priorität entspricht dem Entfernen der Wurzel des Heaps.Dies hinterlässt im Allgemeinen zwei separate Heaps, nämlich den linken und den rechten Teilbaum der Wurzel. Die beiden Heaps werden zusammengeführt in dem der Knoten genommen wird, der auf dem untersten Niveau am weitesten rechts steht, und an der Stelle der Wurzel eingefügt wird. \\
Dadurch wird aber in der Regel die Heap Bedingungen verletzt. Um dies zu korrigieren lässt man die neue Wurzel versickern (\textbf{shift-down}) bis die Bedingungen wieder korrekt sind. Dabei bedeutet ein einzelner Versickerungsschritt das Vertauschen des Schlüssels eines inneren Knotens mit dem grösseren Schlüssel seiner beiden Söhne. \\
Der Aufwand des Versickerns hängt direkt von der Länge des Pfades und somit von der Höhe des Heap ab. Da die Höhe eines balancierten Binärbaumes logarithmisch in der Anzahl der Knoten \textit{(= n)} ist, resultiert gesamthaft eine logarithmische Zeitkomplexität für das Entfernen eines Schlüssels mit höchster Priorität: \textit{O(log n)}.

\subsubsection{Einfügen eines Objektes mit gegebener Priorität}
Das neue Objekt wird am letzten Knoten im Heap eingefügt. Dazu werden alle Knoten im Heap fortlaufend nummerriert. Beginnend bei der Wurzel mit 1, dann alle weiteren Niveaus der Reihe nach und innerhalb der Niveaus von links nach rechts. Auch hier ist es sehr warscheinlich, dass die Heap Bedinungen verletzt werden. Man wenden hier das genau gegenteilige Verfahren an (\textbf{shift-up}): \\
Erfüllt Knoten v die Heap-Bedingung nicht, so wird v mit demjenigen Sohn von v, welcher den grösseren Schlüssel besitzt, vertauscht.

\subsubsection{Entfernen eines Objektes an beliebiger, aber gegebener Position}
Auch bei dieser Operation wird die Nummerierung der Knoten benötigt. Falls der zu entfernende Knoten der letzte Knoten im Heap ist, kann dieser entfernt werden ohne die Heap Bedinungen zu verletzen. Andernfalls wird der zu löschende Knoten v mit dem letzten Knoten p des heaps vertauscht, damit v problemlos gelöscht werden kann. \\
m Allgemeinen wird durch das Vertauschen der beiden Knoten v und p die Heap-Bedingung verletzt, entweder hat p einen grösseren Schlüssel als sein neuer Vater oder p hat einen kleineren Schlüssel als einer seiner neuen Söhne. Im ersteren Fall wird auf dem Pfad von p zur Wurzel die \textbf{sift-up}-Operation angewandt und im letzteren Fall lassen wir p mittels \textbf{sift-down}-Operation versickern.

\subsubsection{Aufbau eines Heaps}
Mit den n Schlüsselwerten bauen wir zuerst einen balancierten Binärbaum auf, so dass alle Blätter auf höchstens zwei verschiedenen Niveaus auftreten und dass auf demjenigen Niveau, wo sowohl innere Knoten als auch Blätter auftreten können, kein innerer Knoten weiter rechts liegt als irgend ein Blatt. Im Allgemeinen wird jedoch die Heap-Bedingung dadurch nicht erfüllt. \\
Bevor wir auf die Umstrukturierung eingehen, zeigen wir den balancierten Binärbaum, welcher aus der Schlüsselmenge { 7, 5, 3, 11, 14, 8, 20, 17 } anfänglich aufgebaut wird. Die Anzahl innerer Knoten ist n = 8.
\begin{center}
\includegraphics[scale=0.4]{heap-unsortiert.png}
\end{center}
Für jeden inneren Knoten, dessen beide Söhne beides Blätter sind, gilt trivialerweise, dass die Heap- Bedingung bereits erfüllt ist. Dies ist der Fall für alle Knoten mit einer Nummer grösser als $(n/2)$. Im oben stehenden Beispiel sind dies die Knoten 5 bis 8. Die restlichen Knoten mit den Nummern 1 bis $(n/2)$ werden nun in der Reihenfolge $(n/2)$, $(n/2)-1$, ..., 1 mit der Operation \textbf{sift-down} versickert. Für oben stehendes Beispiel ergeben sich dadurch die folgenden Veränderungen und schliesslich der unten stehende Heap:\\ \\
- Knoten 4 mit Schlüssel 11 versickern: 7, 5, 3, 17, 14, 8, 20, 11\\
- Knoten 3 mit Schlüssel 3 versickern: 7, 5, 20, 17, 14, 8, 3, 11\\
- Knoten 2 mit Schlüssel 5 versickern: 7, 17, 20, 11, 14, 8, 3, 5\\
- Knoten 1 mit Schlüssel 7 versickern: 20, 17, 8, 11, 14, 7, 3, 5\\
\begin{center}
\includegraphics[scale=0.4]{heap-sortiert.png}
\end{center}

\pagebreak
\section{Hash-Verfahren}
Die grosse Aufgabe bei Datenstrukturen sind die drei Operationen Einfügen, Suchen und Entfernen möglichst schnell anzubieten. Das schnellste bisher sind die AVL-Bäume, die alle drei Operationen in $O(log(n))$ anbieten. Im Gegensatz dazu steht das Array, welches alle drei Operationen in $O(1)$ anbietet. Es kann direkt auf einzelne Speicherzellen zugegriffen werden ohne umständliches Vergleichen und/oder Suchen. Arrays sind aber nicht dynamisch und es ist nicht möglich, ein unendlich langes Array zu haben, sondern es muss auf eine fixe Grösse limitiert werden. Die Hash-Datenstruktuen versuchen das schnelle Array mit der Unlimitiertheit der dynamischen Datenstrukturen zu verbinden.

\subsection{Begriffe}
\begin{description}
	\item[Quellmenge] \hfill \\ Die Menge aller Möglicher Nachrichten.
	\item[Zielmenge] \hfill \\ Menge aller möglichen Hash-Werten. Sie ist im Allgemeinen viel kleiner als die Quellmenge.
	\item[Kollision] \hfill \\ Nachrichten welche den selben Hash-Wert haben.
	\item[Hash-Funktion] \hfill \\ Enthält die Berechnung, die es erlaubt, von einer beliebigen Nachricht einen Hash-Wert fixer Länge zu berechnen.
\end{description}

\subsection{Hash-Funktionen}
\begin{description}
	\item[Divisions-Rest-Methode] \hfill \\
	Ein nahe liegendes Verfahren zur Erzeugung eines Hash-Wertes ist es, den Rest einer ganzzahligen  Division von k durch m zu nehmen: $h(k) = k$ $mod$ $m$. \\
	Für die Qualität dieser Hash-Funktion ist dann allerdings eine geschickte Wahl von m entscheidend. Eine gute Wahl ist eine Primzahl welche kein Teiler einer zweierpotenz ist.
	\item[Multiplikative Methode] \hfill \\
	Der gegebene Schllüsse wird mit einer irrationalen Zahl multipliziert; der ganzzahlige Anteil des Resultats wird abgeschnitten. Auf diese Weise erhält man für verschiedene Schlüssel verschiedene Werte zwischen 0 und 1. Für Schlüssel 1, 2, 3, ..., n sind diese Werte ziemlich gleichmässig im Intervall [0, 1] verstreut.
\end{description}
Jede Hash-Funktion aus H bildet alle denkbar möglichen Schlüsselwerte auf einen Index aus \{0, 1, ..., m-1\} ab. H heisst nun \textbf{universell}, wenn für je zwei verschiedene Schlüsselwerte x und y gilt:
\begin{center}
$\frac{|[h \in H : h(x)=h(y)]|}{|H|} <= \frac{1}{m}$
\end{center} 
H ist also dann universell, wenn für jedes Paar von verschiedenen Schlüsseln höchstens der m-te Teil der Hash-Funktionen aus H zu einer Indexkollision für dieses Schlüsselpaar führen.

\subsection{Verkettung der Überläufer}
Das zu lösende Problem sind die Synonyme. Soll in ein Array, das bereits den Schlüssel k enthält, ein Synonym k' von k eingefügt werden, so ergibt sich eine Indexkollision. Der Platz h(k) = h(k') ist bereits besetzt und k', ein Überläufer, muss anderswo gespeichert werden. Eine einfache Art, Überläufer zu speichern, ist die, sie ausserhalb des Arrays abzulegen, und zwar in dynamisch veränderbaren Strukturen. So kann man etwa die Überläufer zu jedem Array-Index in einer linearen Liste verketten; diese Liste wird an den Array-Eintrag angehängt, der sich durch Anwendung der Hash-Funktion auf die Schlüssel ergibt.

\subsubsection{Separate Verkettung}
Bei der separaten Verkettung der Überläufer ist jedes Element der Hash-Tabelle das Anfangselement einer Überlaufkette (verkettete lineare Liste). Angenommen wir hätten eine Klasse List mit einer inneren Klasse List.Element. Somit können wir ein Array von solchen Elementen als unsere Hash-Tabelle verwenden. 
\begin{center}
\includegraphics[scale=0.4]{hash-separate-verkettung.png}
\end{center}

\subsubsection{Direkte Verkettung}
Bei der direkten Verkettung der Überläufer ist jedes Element der Hash-Tabelle eine eigenständige Liste. In der Hash-Tabelle werden also bloss Referenzen auf Listen gespeichert und die Datensätze in die Listen eingefügt. 
\begin{center}
\includegraphics[scale=0.4]{hash-direkte-verkettung.png}
\end{center}

\subsection{Offene Hash-Verfahren}
Mit der Idee von offenen Hash-Verfahren wird ein Ansatz verfolgt, die Überläufer innerhalb der Hash-Tabelle unterzubringen. Wenn also beim Versuch den Schlüssel k in die Hash- Tabelle an Position h(k) einzutragen festgestellt wird, dass t[h(k)] bereits belegt ist, so muss man nach einer festen Regel einen anderen, nicht belegten Platz finden, an dem man k unterbringen kann. Da man von vornherein nicht weiss, welche Plätze belegt sein werden und welche nicht, definiert man für jeden Schlüssel eine Reihenfolge, in der alle Speicherplätze einer nach dem anderen betrachtet werden. Sobald dann ein betrachteter Platz frei ist, wird der Datensatz dort gespeichert. Die Magie liegt also darin, wie man abhängig vom jeweiligen Schlüssel, die Hash-Tabelle inspiziert. Diese Reihenfolge nennt sich Sondierungsfolge. \\
Um einen Schlüssel zu löschen ohne die Sondierungsreienfolge zu zerstören benötigt es einen kleineen Trick. Er wird nicht wirklich entfernt, sondern lediglich als entfernt markiert. Wird ein neuer Schlüssel eingefügt, so wird der Platz von k als frei angesehen; wird ein Schlüssel gesucht, so wird der Platz von k als belegt angesehen.

\subsubsection{Schema}
Sei s(j,k) eine Funktion von j und k so, dass $(h(k)-s(j,k))$ $mod$ $m$ für j = 0, 1, ..., m-1 eine Sondierungsfolge bildet, d.h. eine Permutation aller Hash-Adressen. Es sei stets noch mindestens ein Platz in der Hash-Tabelle frei.

\subsubsection{Lineares Sondieren}
Beim linearen Sondieren ergibt sich für den Schlüssel k die Sondierungsfolge \\
$h(k), h(k)-1, h(k)-2, h(k)-3, ..., 0, m-1, m-2, m-3, ..., h(k) + 1$ \\
Es wird einfach immer ein Array-Index kleiner versucht, bis der kleinste Index erreicht wird (also 0) und dann wird einfach vom höchsten Index an weiter gesucht. \\
Das Schema ist beim linearen Sondieren die Funktion $s(j,k) = j$.

\subsubsection{Double-Hashing}
Für die Sondierungsfolge wird eine zweite Hash-Funktion verwendet. Die gewählte Sondierungsfolge für Schlüssel k ist \\
$h(k), h(k)-h'(k), h(k)-2*h'(k), ..., h(k)-(m-1)*h'(k)$ \\
wenn h'(k) die zweite Hash-Funktion bezeichnet. Damit wir keine Indizes errechnen, die kleiner 0 sind,
wird das Resultat jeweils noch modulo m gerechnet.

\subsubsection{Implementierung}
\lstinputlisting[language=java,caption=Abstrakte Klasse,style=JavaStyle]{OpenHashMap.java}

\lstinputlisting[language=java,caption=Besipiel,style=JavaStyle]{LinearHashMap.java}

\pagebreak
\section{Graphen}
\end{document}